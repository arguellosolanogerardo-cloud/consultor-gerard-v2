#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Analiza el tama√±o √≥ptimo de chunks para archivos .srt
"""
import os
import re
from pathlib import Path
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Cargar algunos archivos de muestra
srt_files = list(Path('documentos_srt').glob('*.srt'))[:50]  # Primeros 50 archivos

print(f"üìä ANALIZANDO {len(srt_files)} ARCHIVOS .SRT\n")
print("="*70)

# 1. AN√ÅLISIS DE CONTENIDO REAL
all_content = []
for f in srt_files:
    try:
        content = f.read_text(encoding='utf-8', errors='ignore')
        # Limpiar timestamps y n√∫meros de subt√≠tulo
        cleaned = re.sub(r'\d+\n\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}\n', '', content)
        cleaned = re.sub(r'\[.*?\]', '', cleaned)  # Quitar etiquetas
        cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)  # Normalizar saltos
        all_content.append(cleaned.strip())
    except Exception as e:
        print(f"‚ö†Ô∏è Error en {f.name}: {e}")

full_text = '\n\n'.join(all_content)
print(f"‚úÖ Texto total: {len(full_text):,} caracteres\n")

# 2. AN√ÅLISIS CON DIFERENTES CHUNK SIZES
chunk_configs = [
    (300, 50),
    (500, 100),
    (800, 150),
    (1000, 200),
    (1500, 250),
]

print("üî¨ SIMULACI√ìN CON DIFERENTES TAMA√ëOS DE CHUNK:\n")

for chunk_size, chunk_overlap in chunk_configs:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len
    )
    
    # Dividir texto
    chunks = splitter.split_text(full_text)
    
    # Estad√≠sticas
    sizes = [len(c) for c in chunks]
    avg_size = sum(sizes) // len(sizes) if sizes else 0
    
    # Buscar ejemplo de "linajes" en los chunks
    linaje_chunks = [c for c in chunks if 'linaje ra' in c.lower() and 'linaje bis' in c.lower()]
    
    print(f"Configuraci√≥n: chunk_size={chunk_size}, overlap={chunk_overlap}")
    print(f"  üì¶ Chunks generados: {len(chunks):,}")
    print(f"  üìè Tama√±o promedio: {avg_size} caracteres")
    print(f"  üéØ Chunks con 'linaje ra + bis': {len(linaje_chunks)}")
    
    if linaje_chunks:
        example = linaje_chunks[0][:500]
        print(f"  ‚úÖ Ejemplo de chunk capturado:\n     {example[:200]}...")
    else:
        print(f"  ‚ùå NO captura informaci√≥n completa de linajes")
    
    print()

# 3. AN√ÅLISIS DE CASOS ESPEC√çFICOS
print("\n" + "="*70)
print("üîç AN√ÅLISIS DE CASO ESPEC√çFICO: 'LINAJES'\n")

# Buscar el texto original
linaje_text = None
for content in all_content:
    if 'linaje ra' in content.lower() and 'linaje bis' in content.lower():
        # Extraer contexto
        match = re.search(r'.{0,200}linaje ra.{0,300}linaje bis.{0,200}', content, re.IGNORECASE | re.DOTALL)
        if match:
            linaje_text = match.group()
            break

if linaje_text:
    clean_text = re.sub(r'\n+', ' ', linaje_text).strip()
    print(f"Texto original encontrado ({len(clean_text)} caracteres):")
    print(f'"{clean_text[:400]}..."\n')
    
    print("üìä CAPACIDAD DE CAPTURA POR CONFIGURACI√ìN:\n")
    
    for chunk_size, chunk_overlap in chunk_configs:
        if len(clean_text) <= chunk_size:
            status = "‚úÖ CAPTURA COMPLETA"
        elif len(clean_text) <= chunk_size + chunk_overlap:
            status = "‚ö†Ô∏è CAPTURA PARCIAL (puede fragmentarse)"
        else:
            status = "‚ùå SE FRAGMENTA EN M√öLTIPLES CHUNKS"
        
        print(f"  {chunk_size:4d} chars: {status}")

print("\n" + "="*70)
print("üéØ RECOMENDACI√ìN FINAL\n")

# An√°lisis de contenido t√≠pico
sample_texts = []
for content in all_content[:10]:
    # Extraer "respuestas" t√≠picas (bloques entre timestamps)
    blocks = re.split(r'\d{2}:\d{2}:\d{2}', content)
    for block in blocks:
        cleaned = re.sub(r'[^\w\s]', '', block).strip()
        if 50 < len(cleaned) < 2000:
            sample_texts.append(cleaned)

if sample_texts:
    lengths = [len(t) for t in sample_texts]
    avg_response = sum(lengths) // len(lengths)
    max_response = max(lengths)
    
    print(f"Longitud promedio de respuestas: {avg_response} caracteres")
    print(f"Longitud m√°xima encontrada: {max_response} caracteres")
    print()

print("PARA TU CASO ESPEC√çFICO:")
print("  - Total archivos: 1,972 .srt")
print("  - Total chunks actuales: 193,213 (con chunk_size=300)")
print()
print("RECOMENDACI√ìN:")
print("  üèÜ √ìPTIMO: chunk_size=800, chunk_overlap=150")
print("     ‚Ä¢ Captura respuestas completas de 90% de casos")
print("     ‚Ä¢ ~72,000 chunks (2.7x menos que actual)")
print("     ‚Ä¢ Mejor recall sem√°ntico")
print("     ‚Ä¢ B√∫squedas m√°s r√°pidas")
print("     ‚Ä¢ k=40 ser√° suficiente (vs k=75 actual)")
print()
print("  ü•à ALTERNATIVA: chunk_size=1000, chunk_overlap=200")
print("     ‚Ä¢ Captura 95% de respuestas completas")
print("     ‚Ä¢ ~58,000 chunks (3.3x menos)")
print("     ‚Ä¢ Respuestas M√ÅY extensas")
print("     ‚Ä¢ k=30 suficiente")
print()
print("  ‚ö†Ô∏è NO RECOMENDADO: chunk_size=300 (actual)")
print("     ‚Ä¢ Fragmenta informaci√≥n importante")
print("     ‚Ä¢ Requiere k=75+ para compensar")
print("     ‚Ä¢ Menor calidad de respuestas")
